# Project Setup Guide

**Complete setup reference for new developers and LLM threads**  
*Last Updated: January 17, 2026*

---

## ðŸ–¥ï¸ Environment

- **OS**: macOS
- **Python**: 3.11+ via Anaconda (`/opt/anaconda3/bin/python`)
- **Date**: January 2026
- **Data Range**: 1968-2025 (197,911 matches, 7,534 players)
- **Repositories**: 
  - `tml-data/` - Data generation & aggregation
  - `TennisAnalytics/` - Visualizations only

---

## ðŸ“ Repository Structure

```
/Users/saurabhkumar/Desktop/Work/github/
â”‚
â”œâ”€â”€ tml-data/                          # Data Pipeline Repository
â”‚   â”œâ”€â”€ fetch_base_data.py             # Step 1: Download raw data
â”‚   â”œâ”€â”€ build_base_metrics.py          # Step 2: Build base metrics â­ NEW
â”‚   â”œâ”€â”€ run_aggregations.py            # Step 3: Run all analyses
â”‚   â”œâ”€â”€ etl_pipeline.py                # Old monolithic script (deprecated)
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ aggregations/                  # Analysis modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_metrics.py            # Base metrics builder â­ NEW
â”‚   â”‚   â”œâ”€â”€ shared_utils.py            # Common utilities â­ NEW
â”‚   â”‚   â”œâ”€â”€ nbi.py                     # Nailbiter Index
â”‚   â”‚   â”œâ”€â”€ gsdi.py                    # Grand Slam Dominance Index
â”‚   â”‚   â”œâ”€â”€ stantheman.py              # Breakthrough Analysis
â”‚   â”‚   â”œâ”€â”€ network_graph.py           # Network datasets
â”‚   â”‚   â”œâ”€â”€ global_evolution.py        # Geographic trends
â”‚   â”‚   â”œâ”€â”€ career_longevity.py        # Survival analysis
â”‚   â”‚   â””â”€â”€ indian_players.py          # India-specific
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                          # Generated outputs
â”‚   â”‚   â”œâ”€â”€ base/                      # Base metrics â­ NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ atp_matches_base.pkl   # Raw data (197K matches)
â”‚   â”‚   â”‚   â”œâ”€â”€ atp_matches_base.csv   # CSV format
â”‚   â”‚   â”‚   â”œâ”€â”€ player_metrics.pkl     # Player stats (7,534 Ã— 52)
â”‚   â”‚   â”‚   â”œâ”€â”€ player_metrics.csv     # CSV format
â”‚   â”‚   â”‚   â”œâ”€â”€ matches_enriched.pkl   # Enriched matches (197K Ã— 75)
â”‚   â”‚   â”‚   â””â”€â”€ head_to_head_matrix.json # H2H records (112K matchups)
â”‚   â”‚   â”œâ”€â”€ nbi/                       # Nailbiter Index outputs
â”‚   â”‚   â”œâ”€â”€ gsdi/                      # Dominance rankings
â”‚   â”‚   â”œâ”€â”€ stantheman/                # Breakthrough analysis
â”‚   â”‚   â”œâ”€â”€ network/                   # Network graphs (7 files)
â”‚   â”‚   â”œâ”€â”€ globaltop100evolution/     # Global trends (4 files)
â”‚   â”‚   â”œâ”€â”€ career_longevity/          # Survival analysis (6 files)
â”‚   â”‚   â””â”€â”€ indian/                    # India-specific (9 files)
â”‚   â”‚
â”‚   â”œâ”€â”€ code/                          # Jupyter notebooks (legacy/research)
â”‚   â”‚   â”œâ”€â”€ TennisNBI.ipynb
â”‚   â”‚   â”œâ”€â”€ TennisGSCampaign.ipynb
â”‚   â”‚   â”œâ”€â”€ TennisNetworkGraph072025.ipynb
â”‚   â”‚   â””â”€â”€ [others...]
â”‚   â”‚
â”‚   â””â”€â”€ .github/workflows/             # Automation
â”‚       â””â”€â”€ update_data.yml            # Weekly data updates
â”‚
â””â”€â”€ TennisAnalytics/                   # Visualization Repository
    â”œâ”€â”€ index.html                     # Landing page
    â”œâ”€â”€ tennis_analytics.css           # Global styles
    â”‚
    â”œâ”€â”€ stantheman/                    # Breakthrough viz
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ data/                      # Empty (fetches from GitHub)
    â”‚   â””â”€â”€ js/
    â”‚       â”œâ”€â”€ gs_age_distribution_chart.js
    â”‚       â”œâ”€â”€ gs_breakthrough_chart.js
    â”‚       â””â”€â”€ gs_timeline_chart.js
    â”‚
    â”œâ”€â”€ nbi/                           # Nailbiter Index viz
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ nbi.css
    â”‚   â””â”€â”€ data/                      # Empty (fetches from GitHub)
    â”‚
    â”œâ”€â”€ gsdi/                          # Dominance rankings viz
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ gsdi.css
    â”‚   â””â”€â”€ data/                      # Empty (fetches from GitHub)
    â”‚
    â”œâ”€â”€ viz/                           # Network graphs (future)
    â”‚   â”œâ”€â”€ Grand_Slam_Finals_2003.html
    â”‚   â”œâ”€â”€ Australian_Open_Final_1982.html
    â”‚   â””â”€â”€ [others...]
    â”‚
    â”œâ”€â”€ globaltop100evolution/         # Global evolution viz
    â”œâ”€â”€ bigthree/                      # Big 3 analysis
    â”œâ”€â”€ components/                    # Shared UI components
    â”‚   â”œâ”€â”€ header.html
    â”‚   â”œâ”€â”€ footer.html
    â”‚   â”œâ”€â”€ include.js
    â”‚   â””â”€â”€ social-share.js
    â”‚
    â””â”€â”€ image/                         # Assets
        â”œâ”€â”€ claytennis.jpeg
        â””â”€â”€ favicon.ico
```

---

## ðŸ”„ Complete Workflow

### **1. Data Generation (in tml-data/)**

```bash
cd /Users/saurabhkumar/Desktop/Work/github/tml-data

# Step 1: Fetch latest raw data from TML-Database
/opt/anaconda3/bin/python fetch_base_data.py
# Output: data/base/atp_matches_base.pkl (197,911 matches)
# Time: ~2-3 minutes (downloads CSVs from GitHub)

# Step 2: Build base metrics â­ NEW STEP
/opt/anaconda3/bin/python build_base_metrics.py
# Output:
#   - data/base/player_metrics.pkl (7,534 players Ã— 52 columns)
#   - data/base/player_metrics.csv
#   - data/base/matches_enriched.pkl (197,911 matches Ã— 75 columns)
#   - data/base/head_to_head_matrix.json (112,435 matchups)
# Time: ~30 seconds

# Step 3: Generate all analysis outputs
/opt/anaconda3/bin/python run_aggregations.py
# Output: All data/* folders populated (35+ files)
# Time: ~25 seconds (7x faster than old approach!)

# Total pipeline: ~3-4 minutes
```

### **2. Publish Updates**

```bash
# Commit new/updated data files
git add data/
git commit -m "Update data: January 2026 matches"
git push origin main

# TennisAnalytics automatically picks up changes!
# No manual file copying needed - visualizations fetch via:
# https://raw.githubusercontent.com/sorukumar/tml-data/main/data/...
```

### **3. Local Visualization Testing (in TennisAnalytics/)**

```bash
cd /Users/saurabhkumar/Desktop/Work/github/TennisAnalytics

# Start local server for testing
python -m http.server 8000

# Open in browser:
# http://localhost:8000/stantheman/
# http://localhost:8000/nbi/
# http://localhost:8000/gsdi/

# Note: Visualizations fetch data from GitHub even in local testing!
```

---

## ðŸŽ¯ Key Concepts

### **Base Metrics Architecture (NEW!)**

**Before (Monolithic)**:
- Each analysis script recalculated player stats from scratch
- `stantheman.py` looped through 197K matches multiple times
- Score parsing repeated in every analysis
- ~180 seconds total + 60% code duplication

**After (Base Metrics)**:
- Player stats calculated once in `build_base_metrics.py`
- Scores parsed once and stored in `matches_enriched.pkl`
- All analyses consume pre-aggregated data
- ~55 seconds total (3x faster) + 60% less code

**Benefits**:
- âœ… **7x faster** - Base metrics built once, reused everywhere
- âœ… **60% less code** - No duplicated calculations
- âœ… **Consistent metrics** - Single source of truth
- âœ… **Richer data** - Career context ready for tooltips
- âœ… **Maintainable** - Change calculation once, affects all

### **Data Integration Model**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tml-data/                            â”‚
â”‚ â€¢ Generates all data files           â”‚
â”‚ â€¢ Commits to GitHub (main branch)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ Push to GitHub
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Repository                    â”‚
â”‚ â€¢ Hosts data files publicly          â”‚
â”‚ â€¢ Accessible via raw.githubusercontent.com â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ Fetch via HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TennisAnalytics/                     â”‚
â”‚ â€¢ Visualizations only (HTML/JS/CSS) â”‚
â”‚ â€¢ NO local data storage              â”‚
â”‚ â€¢ Fetches data on page load          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points**:
- TennisAnalytics **never** stores data locally
- All data/ folders in TennisAnalytics are **empty placeholders**
- Update flow: Generate â†’ Push â†’ Auto-fetch
- No manual sync/copy scripts needed

---

## ðŸ› ï¸ Running Individual Analyses

### **Run Specific Module**

```bash
cd /Users/saurabhkumar/Desktop/Work/github/tml-data

# Only NBI (uses matches_enriched.pkl)
/opt/anaconda3/bin/python -m aggregations.nbi

# Only GSDI (uses matches_enriched.pkl)
/opt/anaconda3/bin/python -m aggregations.gsdi

# Only StanTheMan (uses player_metrics.pkl) - 0.5s!
/opt/anaconda3/bin/python -m aggregations.stantheman

# Only Network Graphs (uses both base tables)
/opt/anaconda3/bin/python -m aggregations.network_graph

# Only Global Evolution
/opt/anaconda3/bin/python -m aggregations.global_evolution
```

### **Rebuild Only Base Metrics**

```bash
# If you modify base_metrics.py logic
/opt/anaconda3/bin/python build_base_metrics.py

# Then regenerate all analyses
/opt/anaconda3/bin/python run_aggregations.py
```

---

## ðŸ“¦ Dependencies

### **Install Requirements**

```bash
cd /Users/saurabhkumar/Desktop/Work/github/tml-data

# Use Anaconda Python
/opt/anaconda3/bin/pip install -r requirements.txt
```

### **Required Packages**

```
pandas >= 2.0.0
numpy >= 1.24.0
requests >= 2.31.0
```

### **Verify Installation**

```bash
/opt/anaconda3/bin/python -c "import pandas, numpy, requests; print('All dependencies installed!')"
```

---

## ðŸ” Data Verification

### **Check Base Metrics**

```bash
# Verify files exist
ls -lh data/base/

# Expected output:
# atp_matches_base.pkl       (~25 MB)
# atp_matches_base.csv       (~55 MB)
# player_metrics.pkl         (~2 MB)
# player_metrics.csv         (~1 MB)
# matches_enriched.pkl       (~35 MB)
# head_to_head_matrix.json   (~45 MB)
```

### **Quick Python Check**

```python
import pandas as pd
import json

# Load base metrics
players = pd.read_pickle("data/base/player_metrics.pkl")
matches = pd.read_pickle("data/base/matches_enriched.pkl")

print(f"Players: {len(players):,} Ã— {len(players.columns)} columns")
print(f"Matches: {len(matches):,} Ã— {len(matches.columns)} columns")

with open("data/base/head_to_head_matrix.json") as f:
    h2h = json.load(f)
print(f"H2H Matchups: {len(h2h):,}")

# Should see:
# Players: 7,534 Ã— 52 columns
# Matches: 197,911 Ã— 75 columns
# H2H Matchups: 112,435
```

---

## ðŸ› Troubleshooting

### **Issue: Base data fetch fails**

```bash
# Check internet connection
ping github.com

# Check TML-Database availability
curl -I https://raw.githubusercontent.com/Tennismylife/TML-Database/master/2024.csv

# Re-run with error logging
/opt/anaconda3/bin/python fetch_base_data.py 2>&1 | tee fetch_error.log
```

### **Issue: Base metrics build fails**

```bash
# Verify base data exists
ls -lh data/base/atp_matches_base.pkl

# If missing, run fetch first
/opt/anaconda3/bin/python fetch_base_data.py

# Then rebuild metrics
/opt/anaconda3/bin/python build_base_metrics.py
```

### **Issue: Analysis module fails**

```bash
# Check which base files the module needs
# stantheman.py â†’ player_metrics.pkl
# nbi.py â†’ matches_enriched.pkl
# network_graph.py â†’ both!

# Verify files exist
ls -lh data/base/player_metrics.pkl data/base/matches_enriched.pkl

# Run individual module with full traceback
/opt/anaconda3/bin/python -m aggregations.stantheman
```

### **Issue: Visualization shows old data**

```bash
# Check if data was committed to GitHub
cd /Users/saurabhkumar/Desktop/Work/github/tml-data
git status

# If files are uncommitted
git add data/
git commit -m "Update data"
git push origin main

# Clear browser cache or hard refresh (Cmd+Shift+R on macOS)
```

### **Issue: Python not found**

```bash
# Use full Anaconda path
/opt/anaconda3/bin/python --version

# Should see: Python 3.11.x or higher

# If not installed, install Anaconda from:
# https://www.anaconda.com/download
```

---

## âš¡ Quick Commands Cheat Sheet

```bash
# Full pipeline (tml-data)
cd ~/Desktop/Work/github/tml-data
/opt/anaconda3/bin/python fetch_base_data.py && \
/opt/anaconda3/bin/python build_base_metrics.py && \
/opt/anaconda3/bin/python run_aggregations.py

# Rebuild base metrics only
/opt/anaconda3/bin/python build_base_metrics.py

# Run single analysis
/opt/anaconda3/bin/python -m aggregations.nbi

# Test visualization locally (TennisAnalytics)
cd ~/Desktop/Work/github/TennisAnalytics
python -m http.server 8000
# Then open http://localhost:8000

# Check file sizes
du -sh data/*
du -sh data/base/*

# View recent matches
/opt/anaconda3/bin/python -c "
import pandas as pd
df = pd.read_pickle('data/base/atp_matches_base.pkl')
print(df.sort_values('tourney_date', ascending=False).head(10))
"
```

---

## ðŸ“š Documentation Reference

- **ARCHITECTURE.md** - Complete system design, data flow, performance
- **DATA_DICTIONARY.md** - All schemas, column definitions, examples
- **README.md** - Quick overview and getting started
- **This file (SETUP.md)** - Environment setup, workflow, troubleshooting

---

## ðŸŽ“ For New LLM Threads

When starting a new conversation about this project:

1. **Project Context**: Two repos - tml-data (data) + TennisAnalytics (viz)
2. **Architecture**: 3-tier with base metrics layer (NEW since Jan 2026)
3. **Key Files**: Read ARCHITECTURE.md for system design, DATA_DICTIONARY.md for schemas
4. **Workflow**: fetch â†’ build_base_metrics â†’ run_aggregations â†’ push to GitHub
5. **Integration**: TennisAnalytics fetches via GitHub raw URLs (no local data)
6. **Python Path**: Always use `/opt/anaconda3/bin/python` on this macOS system

---

**Last Updated**: January 17, 2026  
**Environment**: macOS, Python 3.11+ (Anaconda)  
**Workspace**: `/Users/saurabhkumar/Desktop/Work/github/`
